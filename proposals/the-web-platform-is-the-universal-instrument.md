The Web Platform is the Universal Instrument
========================

* Speaker   : Ben Michel
* Available : Any time that works for your schedule
* Length    : 30 minutes, but could be any duration as needed

Description
-----------

Music as an idea, expression, commercial endeavor, and communal art is in its most volatile state since the European Renaissance. We’ve moved from the public adoption of recording technology, through the massive rise and fall of the recording industry, to a new age which first seeded at Bell Labs during the Computer Science era. 

Max Mathews encouraged a generation of computer musicians by declaring the Nyquist-Shannon “sampling theorem shows that there are really no limits to the sounds you can make…the computer is a universal musical instrument.”  

With a fuller understanding of what Mathews was implying, we can now take it a step further and say that the Browser is the universal musical instrument, being the most accessible and cross-compatible runtime yet–and with the growth of Web Audio and Web MIDI standardization, we’re on the verge of a new renaissance in musical collaboration and interaction. 

Unfortunately, the promotion of individualism in our popular culture has kept us from realizing the potential of developing better methods of communal collaboration, even in the web platform. 

Still, I can see a world coming where community music and musical works are not identified by regions boundaries, but distributed data regions and organic peer to peer networks. If the development of Web Audio and it’s supporting standards stabilize, sonic collaboration and exposition could be made available to everyone with no hinderances from age, class, or personal ability.

The WebSound project is my iterative solution to this problem through long-term community engagement, and Audio & MIDI tool versioning.

Our first endeavor is to build a few useful live performance tools enabling remote collaboration:
Realtime Web MIDI performances streamed to a remote live-event, enabling the performer to lead songs or compositions remotely. Achieved through an optimized VPN and P2P WebRTC DataChannels.
Communally performed live music making with MIDI controlled WebAudio and WebSocket broadcasting.
Audience interaction with the exposed parameters of a live band’s instrumentation–via broadcast methods and microcontroller installations.

Demo Description 
A WebMIDI remote performance. The remote player leads a song that I perform with live at NodePDX, as well as giving an invitation to the audience to participate (which may involve MIDI participation, karaoke-style singing, or both). 

Developer Takeaway 
Developers will be able to better understand how simple peer2peer networks and protocols like WebRTC can become a very powerful asset to the Web Audio and MIDI APIs–and have the potential to change the way we do music. They will also be invited to get involved with the WebSound project at the end of the demonstration.

---------------

Speaker Bio
-----------

Musician–Developer. I compose & perform live soundtracks, and care a lot about community music.

Links
-----

* Github: https://github.com/websound/WebSound
* Soundcloud: http://soundcloud.com/benmichelmusic
